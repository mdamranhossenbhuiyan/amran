<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title> Md Amran Hossen Bhuiyan </title>

    <meta name="author" content="Md Amran Hossen Bhuiyan">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Md Amran Hossen Bhuiyan
                </p>
                <p>
			I am currently a Postdoctoral Researcher in the <a href="https://www.yorku.ca/jhuang/irlab/">Information Retrieval and Knowledge Management Lab (IRLAB)</a> at York University, led by <a href="https://profiles.laps.yorku.ca/profiles/jhuang/">Professor Jimmy Huang</a>, where I contribute to AI research at the intersection of computer vision and contextual information retrieval, with a focus on multimodal settings and improving model generalization.
                </p>
                <p>

                 
I earned my Ph.D. from the <a href="https://pavis.iit.it/" >Istituto Italiano di Tecnologia</a> in Genova, Italy, where I was supervised by <a href="https://www.vittoriomurino.com/" >Prof. Vittorio Murino</a>. During my doctoral studies, I spent six months as a visiting research scientist at the <a href="https://vcg.engr.ucr.edu/" >Video Computing Group</a> at the <a href= "https://www.ucr.edu/" >University of California</a>, Riverside, guided by  <a href="https://vcg.engr.ucr.edu/amit" >Amit K. Roy-Chowdhury</a>in 2016. Prior to my Ph.D., I completed my Master's degree at the <a href= "https://www.ulbsibiu.ro/en/">Lucian Blaga University of Sibiu</a>  in Romania, as a recipient of the Erasmus Mundus External Window scholarship program.

                </p>
                <p style="text-align:center">
                  <a href="mailto:amran.apece@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/Curriculum_vitae_Lakehead.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=GvSAjYAAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/mdamranhossenbhuiyan">Github</a> &nbsp;/&nbsp;
				  <a href="https://www.linkedin.com/in/md-amran-hossen-bhuiyan-58007029/">LinkdIn</a> 
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/Amran_image.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/Amran_image.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  My expertise lies in computer vision, machine learning, and natural language processing, with a focus on creating efficient AI solutions for large-scale data analysis. My work, which includes projects in person re-identification, multi-camera tracking, and deep learning, aims to develop advanced algorithms for applications such as video surveillance and image recognition. This research not only contributes to the academic field but also has practical applications in various industries, including security and media.            </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>News</h2>
                <ul style="margin-left: 15px; width: 812px;">

					  </li>

<li>One paper title as <a href ="https://www.arxiv.org/pdf/2507.03280">"Modeling Item-Level Dynamic Variability with Residual Diffusion for Bundle Recommendation"</a> accepted in: <a href="https://aaai.org/conference/aaai/aaai-26/">AAAI 2026.</li>

  
				  </li>

<li>One paper title as <a href ="https://arxiv.org/pdf/2510.07545?">"Deploying Tiny LVLM Judges for Real-World Evaluation of Chart Models: Lessons Learned and Best Practices"</a> accepted in: <a href="https://2025.emnlp.org/">EMNLP 2025</a>, Industry Track</a>.</li>

		
				</li>

<li>One paper title as <a href =https://arxiv.org/pdf/2505.08468?>"Judging the Judges: Can Large Vision-Language Models Fairly Evaluate Chart Comprehension and Reasoning?" </a> accepted in: <a href="https://2025.aclweb.org/">ACL 2025</a>, Industry Track</a>.</li>

			

<li>Two papers accepted in early 2025: <a href="https://www.sciencedirect.com/science/article/pii/S0031320325000160">Pattern Recognition</a> (Impact Factor: 7.5) and <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/coin.70024">Computational Intelligence</a>.</li>
	
			<li>Paper accepted in the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP) explores <a href= https://arxiv.org/pdf/2407.04069?> A Systematic Survey and Critical Review on
Evaluating Large Language Models </a> <br>
					
               <li>Paper accepted in <a href ="https://arxiv.org/pdf/2403.00784"> ACM Computing Surveys explores Encoder-based BERT for Information Retrieval in contrast to decoder-based LLMs </a>, boasting an impact factor of 16.6!<br>
  
		
  
                </li>
			
                </li>
                <li>Paper on <a href="data/1-s2.0-S1077314223002850-main.pdf" target="_blank"> Domain Generalizable Person Re-identification </a> accepted at <a href="https://www.sciencedirect.com/journal/computer-vision-and-image-understanding" target="_blank">CVIU 2023</a>.<br>
  
                </li>
  
                <li>Paper on <a target="_blank" href="data/acl_gpt.pdf">Evaluation of ChatGPT</a> accepted at <a href="https://2023.aclweb.org/" target="_blank">ACL 2023</a>.<br>
  
                </li>
  
                <li>Paper on <a href="data/US_Patent.pdf" target="_blank"> Identity Preservative Representation of Persons and Objects</a> accepted at <a href="https://patents.google.com/patent/US20220383662A1/en" target="_blank">US  Patents 2022</a>.<br>
  
                </li>
  
                <li>Paper on  <a href="data/1-s2.0-S0262885622001032-main.pdf" target="_blank">Spatio-temporal cross-attention network for video person re-identification</a> accepted at <a href="https://www.sciencedirect.com/journal/image-and-vision-computing" target="_blank"> IVC 2022</a>.</li>
  
              
                <li>Paper on <a href="data/s13640-021-00562-6.pdf" target="_blank">Exploiting prunability for person re-identification</a> accepted in <a href="https://jivp-eurasipjournals.springeropen.com/" target="_blank">EURASIP Journal on Image and Video Processing 2021</a>.<br>
  
                </li>
  
                <li>Paper on <a href="data/1-s2.0-S0262885621001517-main.pdf" target="_blank">Flow guided mutual attention for person re-identification</a> accepted in IVC 2021.
  
                </li>
  
                <li>Paper on <a href="data/Bhuiyan_Pose_Guided_Gated_Fusion_for_Person_Re-identification_WACV_2020_paper.pdf" target="_blank"> Pose Guided Gated Fusion for Person Re-identification</a> accepted at <a href="https://openaccess.thecvf.com/content_WACV_2020/html/Bhuiyan_Pose_Guided_Gated_Fusion_for_Person_Re-identification_WACV_2020_paper.html" target="_blank">WACV 2020</a>.<br>
  
                </li>

                <li>Paper on <a href="data/2007.13890.pdf" target="_blank"> Unsupervised Domain Adaptation in the Dissimilarity Space for Person Re-identification</a> accepted at <a href="https://link.springer.com/chapter/10.1007/978-3-030-58583-9_10" target="_blank">ECCV 2020</a>.<br>
  
                </li>
                <li>Paper on <a href="data/PR_2019.pdf" target="_blank"> Adaptation of person re-identification models for on-boarding new camera(s)</a> accepted at <a href="https://www.sciencedirect.com/journal/pattern-recognition" target="_blank"> Pattern Recognition 2019</a>.<br>
  
                </li>
              </li>
              <li>Paper on <a href="https://ieeexplore.ieee.org/abstract/document/8909838" target="_blank"> RGB-Depth Cross-Modal Person Re-identification</a> accepted at <a href="https://ieeexplore.ieee.org/xpl/conhome/1001307/all-proceedings" target="_blank"> AVSS 2019</a>.<br>

              </li>

            </li>
            <li>Paper on <a href="data/CVPR_2017_RD.pdf" target="_blank"> Unsupervised Adaptive Re-identification in Open World Dynamic Camera Networks</a> accepted at <a href="https://ieeexplore.ieee.org/xpl/conhome/8097368/proceeding" target="_blank"> CVPR 2017 </a>. <strong>(Spotlight)</strong><br>

            </li>

          </li>
          <li>Paper on <a href="https://ieeexplore.ieee.org/abstract/document/7351218" target="_blank"> Exploiting multiple detections to learn robust brightness transfer functions </a> accepted at <a href="https://ieeexplore.ieee.org/xpl/conhome/7328364/proceeding" target="_blank"> ICIP 2015</a>. <strong> (Oral)</strong><br>

          </li>
          <li>Paper on <a href="data/05 -Person re-identification by discriminatively.pdf" target="_blank"> discriminatively
            selecting parts and features </a> accepted at <a href="https://link.springer.com/chapter/10.1007/978-3-319-16199-0_11" target="_blank"> ECCV-WK 2014 </a>. <strong> (Winner of the INTEL Best paper award )</strong>

  .            </td>
            </tr> </ul>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>




<!-- Work Experience (section header) -->
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>
    <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <h2>Work Experience</h2>
        <p></p>
      </td>
    </tr>
  </tbody>
</table>

<!-- Work Experience (entries) -->
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>

    <tr>
      <td style="padding:10px 20px;width:100%;vertical-align:middle">
        <p style="margin:0;font-size:22px;font-weight:700;">Postdoctoral Research Fellow @ York University</p>
        <p style="margin:6px 0 0 0;font-size:20px;">May 2022 to Present</p>
      </td>
    </tr>

    <tr>
      <td style="padding:10px 20px;width:100%;vertical-align:middle">
        <p style="margin:0;font-size:22px;font-weight:700;">Deep Learning Advisor @ Veyetals, MarkiTech.AI</p>
        <p style="margin:6px 0 0 0;font-size:20px;">February 2024 to December 2024</p>
      </td>
    </tr>

    <tr>
      <td style="padding:10px 20px;width:100%;vertical-align:middle">
        <p style="margin:0;font-size:22px;font-weight:700;">Adjunct Faculty @ York University</p>
        <p style="margin:6px 0 0 0;font-size:20px;">January 2023 to Present</p>
      </td>
    </tr>

    <tr>
      <td style="padding:10px 20px;width:100%;vertical-align:middle">
        <p style="margin:0;font-size:22px;font-weight:700;">Instructor @ York University (SMART-ART Summer Courses – Introduction to AI)</p>
        <p style="margin:6px 0 0 0;font-size:20px;">June 13, 2022 to June 20, 2022</p>
      </td>
    </tr>

    <tr>
      <td style="padding:10px 20px;width:100%;vertical-align:middle">
        <p style="margin:0;font-size:22px;font-weight:700;">Industrial Postdoctoral Fellow @ ÉTS &amp; SPORTLOGiQ Inc.</p>
        <p style="margin:6px 0 0 0;font-size:20px;">January 2018 to March 2021</p>
      </td>
    </tr>

    <tr>
      <td style="padding:10px 20px;width:100%;vertical-align:middle">
        <p style="margin:0;font-size:22px;font-weight:700;">Visiting Scholar (Research Intern) @ University of California, Riverside</p>
        <p style="margin:6px 0 0 0;font-size:20px;">May 2016 to October 2016</p>
      </td>
    </tr>

    <tr>
      <td style="padding:10px 20px;width:100%;vertical-align:middle">
        <p style="margin:0;font-size:22px;font-weight:700;">Doctoral Student Researcher @ Istituto Italiano di Tecnologia (IIT)</p>
        <p style="margin:6px 0 0 0;font-size:20px;">March 2014 to April 2017</p>
      </td>
    </tr>

    <tr>
      <td style="padding:10px 20px;width:100%;vertical-align:middle">
        <p style="margin:0;font-size:22px;font-weight:700;">Associate Professor &amp; Assistant Professor @ Noakhali Science and Technology University</p>
        <p style="margin:6px 0 0 0;font-size:20px;">March 2021 to May 2022; and March 2012 to December 2017</p>
      </td>
    </tr>

  </tbody>
</table>

			  


          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Selected Publications</h2>
                <p>
                 
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr onmouseout="PR25_stop()" onmouseover="PR25_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
                <img src='images/PR25.jpg' width=130%>
        </div>
        <script type="text/javascript">
          function PR25_start() {
            document.getElementById('PR25').style.opacity = "1";
          }

          function PR25_stop() {
            document.getElementById('PR25').style.opacity = "0";
          }
          PR25_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://www.sciencedirect.com/science/article/pii/S0031320325000160">
          <span class="papertitle">Optimizing domain-generalizable ReID through non-parametric normalization</span>
        </a>
        <br>
	
		<strong>Amran Bhuiyan</strong>,
         <a href="https://www.yorku.ca/jhuang/">Jimmy X. Huang</a>,
          <a href="http://www.cse.yorku.ca/~aan/"> Aijun An</a>
	   <a href="https://www.citystgeorges.ac.uk/about/people/academics/jialie-shen">  Jialie Shen </a>  
          <br>
          <em>Pattern Recognition</em>, 2025
          <br>
          <br>

        
Optimizing deep neural networks to generalize effectively across diverse visual domains remains a key challenge in computer vision, especially in domain-generalizable person re-identification (ReID). The goal of domain-generalizable ReID is to develop robust deep learning (DL) models that are effective across both known (source) and unseen (target) domains. However, many top-performing ReID methods overfit to the source domain, impairing their generalization ability. Previous approaches have employed Instance Normalization (IN) with learnable parameters to generalize domains and eliminate source domain styles. Recently, some DL frameworks have adopted normalization techniques without learnable parameters. We critically examine non-parametric normalization techniques for optimizing the deep ReID model, emphasizing the advantages of using non-parametric instance normalization as a gating mechanism to extract style-independent features at various abstraction levels within both convolutional neural networks (CNNs) and Vision Transformers (ViT). Our framework offers strategic guidance on the optimal placement of non-parametric IN within the network architecture to ensure effective information flow management in subsequent layers. Additionally, we employ one-dimensional Batch Normalization (BN) without learnable parameters at deeper network levels to remove content-related biases from the source domain. Our integrated approach, termed DualNormNP, systematically optimizes the model’s capacity to generalize across varied domains. Comprehensive evaluations on multiple benchmark ReID datasets demonstrate that our approach surpasses current state-of-the-art ReID methods in terms of generalization performance.        </p>
      </td>
    </tr>
	
		  

    <tr onmouseout="IGMG_stop()" onmouseover="IGMG_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
                <img src='images/IGMG.png' width=130%>
        </div>
        <script type="text/javascript">
          function IGMG_start() {
            document.getElementById('IGMG_image').style.opacity = "1";
          }

          function IGMG_stop() {
            document.getElementById('IGMG_image').style.opacity = "0";
          }
          IGMG_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://www.sciencedirect.com/science/article/pii/S1077314223002850/">
          <span class="papertitle">IGMG: Instance-guided multi-granularity for domain generalizable person
            re-identification</span>
        </a>
        <br>
	
		<strong>Amran Bhuiyan</strong>,
         <a href="https://www.yorku.ca/jhuang/">Jimmy X. Huang</a>,
          <a href="http://www.cse.yorku.ca/~aan/"> Aijun An</a>
          <br>
          <em>Computer Vision and Image Understanding (CVIU)</em>, 2024
          <br>
          <br>

        
The effectiveness of multi-granularity methods in addressing domain shift issues in person re-identification is investigated, and a novel framework called Instance-Guided Multigranularity (IGMG) is introduced, which employs non-parametric Instance Normalization (IN) for processing style-free features at different levels of detail, thereby improving the model's generalization through the utilization of shareable low and mid-level features.
        </p>
      </td>
    </tr>
	
      


    <tr onmouseout="GPT_stop()" onmouseover="GPT_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
                <img src='images/chatgpt.png' width=130%>
        </div>
        <script type="text/javascript">
          function GPT_start() {
            document.getElementById('GPT_image').style.opacity = "1";
          }

          function GPT_stop() {
            document.getElementById('GPT_image').style.opacity = "0";
          }
          GPT_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2305.18486.pdf">
          <span class="papertitle">A Systematic Study and Comprehensive Evaluation of ChatGPT on
            Benchmark Datasets</span>
        </a>
        <br>
	
        <a href="https://sites.google.com/view/tahmedge/home"> Md Tahmid Rahman Laskar</a>,
        <a href="https://sbmaruf.github.io/"> M Saiful Bari</a>,
        <a href="https://scholar.google.com/citations?user=SzJtFg8AAAAJ&hl=en"> Mizanur Rahman</a>,
		<strong>Amran Bhuiyan</strong>,
    <a href="https://raihanjoty.github.io/"> Shafiq Joty</a>,

         <a href="https://www.yorku.ca/jhuang/">Jimmy X. Huang</a>
         
          <br>
          <em> Association for Computational Linguistics  (ACL' 23 Findings)</em>, 2023
          <br>
          <br>

        
          This paper conducts an extensive assessment of ChatGPT's performance across a wide range of academic datasets including tasks such as question answering, text summarization, code generation, commonsense reasoning, mathematical problem-solving, machine translation, bias detection, and ethical considerations. The evaluation covers 140 tasks and analyzes 255K responses, marking the most comprehensive evaluation of ChatGPT within NLP benchmarks. Ultimately, this study aims to evaluate ChatGPT's strengths and weaknesses across diverse tasks and offer valuable insights for future research employing Large Language Models (LLMs).        </p>
      </td>
    </tr>
	
      

    <tr onmouseout="USP_stop()" onmouseover="USP_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
                <img src='images/uspatent.png' width=130%>
        </div>
        <script type="text/javascript">
          function USP_start() {
            document.getElementById('USP_image').style.opacity = "1";
          }

          function USP_stop() {
            document.getElementById('USP_image').style.opacity = "0";
          }
          USP_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://patents.google.com/patent/US20220383662A1/en">
          <span class="papertitle">System and Method for Identity Preservative Representation of Persons and Objects Using Spatial and Appearance Attributes</span>
        </a>
        <br>
	
        <a href="https://scholar.google.com/citations?user=3S8O0b4AAAAJ&hl=fr"> Mehrsan Javan Roshtkhari </a>,
       
		<strong>Amran Bhuiyan</strong>,
    <a> Yang Liu </a>,
    <a href="https://scholar.google.com/citations?user=vNFjHYMAAAAJ&hl=fr"> Parthipan Siva </a>,

    <a href="https://www.etsmtl.ca/en/research/professors/egranger"> Eric Granger</a>,

         <a href="https://profs.etsmtl.ca/ibenayed/">Ismail Ben Ayed</a>
         
          <br>
          <em> US Patent </em>, 2022
          <br>
          <br>

        
          The method involves processing images to create unique identity-preserving descriptors for individuals or objects by extracting and combining spatial and appearance attributes, and then using these descriptors to differentiate and compare various entities using a predefined mathematical distance metric.      </td>
    </tr>

    
    <tr onmouseout="STCA_stop()" onmouseover="STCA_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
                <img src='images/STCA.png' width=130%>
        </div>
        <script type="text/javascript">
          function STCA_start() {
            document.getElementById('STCA_image').style.opacity = "1";
          }

          function STCA_stop() {
            document.getElementById('STCA_image').style.opacity = "0";
          }
          STCA_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://www.sciencedirect.com/science/article/pii/S0262885622001032">
          <span class="papertitle">STCA: Utilizing a spatio-temporal cross-attention network for enhancing video person re-identification</span>
        </a>
        <br>
	
		<strong>Amran Bhuiyan</strong>,
         <a href="https://www.yorku.ca/jhuang/">Jimmy X. Huang</a>
       
          <br>
          <em>Image and Vision Computing (IVC)</em>, 2022
          <br>
          <br>

        
          We propose a Spatio Temporal Cross Attention (STCA) network to generate cross guided attention for video re-identification that  leverages 2D and 3D-CNNs to identify salient features in videos, enhancing recognition accuracy through attention-based gating and optimized by cosine distance for efficient and precise video re-identification.        </p>
      </td>
    </tr>
  
    <tr onmouseout="prun_stop()" onmouseover="prun_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
                <img src='images/Pruning.png' width=130%>
        </div>
        <script type="text/javascript">
          function prun_start() {
            document.getElementById('prun_image').style.opacity = "1";
          }

          function prun_stop() {
            document.getElementById('prun_image').style.opacity = "0";
          }
          prun_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://link.springer.com/article/10.1186/s13640-021-00562-6">
          <span class="papertitle">Exploiting prunability for person re-identification</span>
        </a>
        <br>
        <a> Hugo Masson * </a>,             
        <strong>Amran Bhuiyan * </strong>,
        <a href="https://scholar.google.ca/citations?user=DAHHOegAAAAJ&hl=en"> Le Thanh nguyen-meidine * </a>,        
        <a href="https://scholar.google.com/citations?user=3S8O0b4AAAAJ&hl=fr"> Mehrsan Javan Roshtkhari </a>,
        <a href="https://scholar.google.com/citations?user=vNFjHYMAAAAJ&hl=fr"> Parthipan Siva </a>,
        <a href="https://profs.etsmtl.ca/ibenayed/">Ismail Ben Ayed</a>,    
        <a href="https://www.etsmtl.ca/en/research/professors/egranger"> Eric Granger</a>
        <strong> (* Equal Contribution)</strong>
    
           
             
       
          <br>
          <em> EURASIP Journal on Image and Video Processing </em>, 2021
          <br>
          <br>

        
          In this paper, we investigate the prunability of the different CNN architectures under different design scenarios. This paper first revisits pruning techniques that are suitable for reducing the computational complexity of deep CNN networks applied to person re-identification. Then, these techniques are analyzed according to their pruning criteria and strategy and according to different scenarios for exploiting pruning methods to fine-tuning networks to target domains.      </td>
    </tr>
      
    <tr onmouseout="flow_stop()" onmouseover="flow_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
                <img src='images/flow.png' width=130%>
        </div>
        <script type="text/javascript">
          function flow_start() {
            document.getElementById('flow_image').style.opacity = "1";
          }

          function flow_stop() {
            document.getElementById('flow_image').style.opacity = "0";
          }
          flow_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://www.sciencedirect.com/science/article/pii/S0262885621001517">
          <span class="papertitle">Flow guided mutual attention for person re-identification</span>
        </a>
        <br>
        <a href="https://scholar.google.com/citations?user=ccEjIYsAAAAJ&hl=en"> Madhu Kiran </a>,            
        <strong>Amran Bhuiyan  </strong>,
        <a href="https://scholar.google.ca/citations?user=DAHHOegAAAAJ&hl=en"> Le Thanh nguyen-meidine * </a>,        
        <a href="https://scholar.google.com/citations?user=3S8O0b4AAAAJ&hl=fr"> Mehrsan Javan Roshtkhari </a>,
        <a> Louis-Antoine Blais-Morin</a>
             <a href="https://profs.etsmtl.ca/ibenayed/">Ismail Ben Ayed</a>,    
        <a href="https://www.etsmtl.ca/en/research/professors/egranger"> Eric Granger</a>
        
    
           
             
       
          <br>
          <em> Image and Video Computing </em>, 2021
          <br>
          <br>

        
           In this paper, the motion pattern of a person is explored as an additional cue for ReID. In particular, a flow-guided Mutual Attention network is proposed for fusion of bounding box and optical flow sequences
          over tracklets using any 2D-CNN backbone, allowing to encode temporal information along with spatial appearance information. Our Mutual Attention network relies on the joint spatial attention between image and optical
          flow feature maps to activate a common set of salient features.    </tr>
      


          <tr onmouseout="pose_stop()" onmouseover="pose_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                      <img src='images/pose.png' width=130%>
              </div>
              <script type="text/javascript">
                function pose_start() {
                  document.getElementById('pose_image').style.opacity = "1";
                }
      
                function pose_stop() {
                  document.getElementById('pose_image').style.opacity = "0";
                }
                pose_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_WACV_2020/papers/Bhuiyan_Pose_Guided_Gated_Fusion_for_Person_Re-identification_WACV_2020_paper.pdf">
                <span class="papertitle">Pose Guided Gated Fusion for Person Re-identification</span>
              </a>
              <br>
              <strong>Amran Bhuiyan  </strong>,
              <a> Yang Liu </a>,            
             
              <a href="https://scholar.google.ca/citations?user=DAHHOegAAAAJ&hl=en"> Le Thanh nguyen-meidine * </a>,  
              <a href="https://scholar.google.com/citations?user=vNFjHYMAAAAJ&hl=fr"> Parthipan Siva </a>,      
              <a href="https://scholar.google.com/citations?user=3S8O0b4AAAAJ&hl=fr"> Mehrsan Javan Roshtkhari </a>,
                               <a href="https://profs.etsmtl.ca/ibenayed/">Ismail Ben Ayed</a>,    
              <a href="https://www.etsmtl.ca/en/research/professors/egranger"> Eric Granger</a>
              
          
                 
                   
             
                <br>
                <em>  Winter Conference on Applications of Computer Vision (WACV) </em>, 2020
                <br>
                <br>
      
              
                In this paper, a new deep learning model is proposed for pose-guided re-identification, comprised of a deep back- bone, pose estimation, and gated fusion network. Given a query image of an individual, the backbone convolutional NN produces a feature embedding required for pair-wise matching with embeddings for reference images, where fea- ture maps from the pose network and from mid-level CNN layers are combined by the gated fusion network to gen- erate pose-guided gating. The proposed framework al- lows to dynamically activate the most discriminant CNN filters based on pose information in order to perform a finer grained recognition.  
                </tr>
            
                <tr onmouseout="eccv_stop()" onmouseover="eccv_start()">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <div class="one">
                            <img src='images/ECCV.png' width=130%>
                    </div>
                    <script type="text/javascript">
                      function eccv_start() {
                        document.getElementById('eccv_image').style.opacity = "1";
                      }
            
                      function eccv_stop() {
                        document.getElementById('eccv_image').style.opacity = "0";
                      }
                      eccv_stop()
                    </script>
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="https://link.springer.com/chapter/10.1007/978-3-030-58583-9_10">
                      <span class="papertitle">Unsupervised Domain Adaptation in the Dissimilarity Space for Person Re-identification</span>
                    </a>
                    <br>
                    <a> Djebril Mekhazni</a>, 
                    <strong>Amran Bhuiyan  </strong>,
                               
                   
                    <a href="https://scholar.google.ca/citations?user=jBw0esEAAAAJ&hl=en"> George S. Eskander Ekladious</a>,  
                                       <a href="https://www.etsmtl.ca/en/research/professors/egranger"> Eric Granger</a>
                    
                
                       
                         
                   
                      <br>
                      <em>  European Conference on Computer Vision (ECCV) </em>, 2020
                      <br>
                      <br>
            
                    
                      In this paper, we propose a novel Dissimilarity-based Maximum Mean Discrepancy (D-MMD) loss for aligning pair-wise distances that can be optimized via gradient descent using relatively small batch sizes. From a person ReID perspective, the evaluation of D-MMD loss is straightforward since the tracklet information (provided by a person tracker) allows to label a distance vector as being either within-class (within-tracklet) or between-class (between-tracklet). This allows approximating the underlying distribution of target pair-wise distances for D-MMD loss optimization, and accordingly align source and target distance distributions. Empirical results with three challenging benchmark datasets show that the proposed D-MMD loss decreases as source and domain distributions become more similar.                      
                    </tr>

     
                    <tr onmouseout="adap_stop()" onmouseover="adap_start()">
                      <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                                <img src='images/adap.png' width=130%>
                        </div>
                        <script type="text/javascript">
                          function adap_start() {
                            document.getElementById('adap_image').style.opacity = "1";
                          }
                
                          function adap_stop() {
                            document.getElementById('adap_image').style.opacity = "0";
                          }
                          adap_stop()
                        </script>
                      </td>
                      <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://www.sciencedirect.com/science/article/pii/S0031320319302948?via%3Dihub">
                          <span class="papertitle">Unsupervised Domain Adaptation in the Dissimilarity Space for Person Re-identification</span>
                        </a>
                        <br>
                        <a href="https://rpand002.github.io/"> Rameswar Panda</a>,
                        <strong>Amran Bhuiyan  </strong>,
                        <a href="https://www.vittoriomurino.com/"> Vittorio Murino </a>,
                       
                        <a href="https://vcg.engr.ucr.edu/amit"> Amit K. Roy-Chowdhury</a>  
                                          
                    
                           
                             
                       
                          <br>
                          <em>  Pattern Recognition (PR) </em>, 2019.
                          <br>
                          <br>
                
                        
                          This paper extends our CVPR 2017 paper providing a new source-target selective adaptation strategy and rigorous experiments on more person re-id datasets.                        
                        </tr>



                        <tr onmouseout="avss_stop()" onmouseover="avss_start()">
                          <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">
                                    <img src='images/avss.png' width=130%>
                            </div>
                            <script type="text/javascript">
                              function avss_start() {
                                document.getElementById('avss_image').style.opacity = "1";
                              }
                    
                              function avss_stop() {
                                document.getElementById('avss_image').style.opacity = "0";
                              }
                              avss_stop()
                            </script>
                          </td>
                          <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8909838">
                              <span class="papertitle">RGB-Depth Cross-Modal Person Re-identification</span>
                            </a>
                            <br>
                            <a href="https://scholar.google.de/citations?user=WjSEMcAAAAAJ&hl=de"> Frank M. Hafner </a>, 
                            <strong>Amran Bhuiyan  </strong>,
                            <a href="https://jkooij.github.io/"> Julian F. P. Kooij </a>, 
                           
                            <a href="https://www.etsmtl.ca/en/research/professors/egranger"> Eric Granger</a>
                                              
                        
                               
                                 
                           
                              <br>
                              <em>   IEEE Conference on Advanced Video and Signal Based Surveillance (AVSS)</em>, 2019.
                              <br>
                              <br>
                    
                            
                              We develop a novel cross-modal distillation network for robust
                              person re-identification, which learns a shared feature representation space of person’s appearance in both RGB and
                              depth images.     
                            
                            </tr>



                              <tr onmouseout="cvpr_stop()" onmouseover="cvpr_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                  <div class="one">
                                          <img src='images/cvpr.png' width=130%>
                                  </div>
                                  <script type="text/javascript">
                                    function cvpr_start() {
                                      document.getElementById('cvpr_image').style.opacity = "1";
                                    }
                          
                                    function cvpr_stop() {
                                      document.getElementById('cvpr_image').style.opacity = "0";
                                    }
                                    cvpr_stop()
                                  </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                  <a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Panda_Unsupervised_Adaptive_Re-Identification_CVPR_2017_paper.pdf">
                                    <span class="papertitle">Unsupervised Adaptive Re-identification in Open World Dynamic Camera Networks</span>
                                  </a>
                                  <br>
                                  <a href="https://rpand002.github.io/"> Rameswar Panda *</a>,
                                  <strong>Amran Bhuiyan*  </strong>,
                                  <a href="https://www.vittoriomurino.com/"> Vittorio Murino </a>, 
                                 
                                  <a href="https://vcg.engr.ucr.edu/amit"> Amit K. Roy-Chowdhury</a>  
                                                    
                              <strong> (* Equal Contribution) </strong>
                                     
                                       
                                 
                                    <br>
                                    <em>  IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2017.
                                    <br>
                                    <br>
                          
                                  
                                    We propose an unsupervised adaptation scheme for re-identification models where a new camera may be temporarily inserted into an existing system to get additional information.   
                                                            </tr>

                                                            <tr onmouseout="avss17_stop()" onmouseover="avss17_start()">
                                                              <td style="padding:20px;width:25%;vertical-align:middle">
                                                                <div class="one">
                                                                        <img src='images/avss17.png' width=130%>
                                                                </div>
                                                                <script type="text/javascript">
                                                                  function avss17_start() {
                                                                    document.getElementById('avss17_image').style.opacity = "1";
                                                                  }
                                                        
                                                                  function avss17_stop() {
                                                                    document.getElementById('avss17_image').style.opacity = "0";
                                                                  }
                                                                  avss17_stop()
                                                                </script>
                                                              </td>
                                                              <td style="padding:20px;width:75%;vertical-align:middle">
                                                                <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8078470">
                                                                  <span class="papertitle">Exploiting Gaussian Mixture Importance for Person Re-identification</span>
                                                                </a>
                                                                <br>
                                                                <a> Xiangping Zhu </a>, 
                                                                <strong> Amran Bhuiyan  </strong>,
                                                                <a href="https://scholar.google.it/citations?hl=en&user=IKK5oMYAAAAJ&view_op=list_works&sortby=pubdate"> Mohamed Lamine Mekhalfi</a>,
                                                                <a href="https://www.vittoriomurino.com/"> Vittorio Murino </a>
                                                               
                                                                
                                                                                  
                                                           
                                                                   
                                                                     
                                                               
                                                                  <br>
                                                                  <em>  14th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)</em>, 2017.
                                                                  <br>
                                                                  <br>
                                                        
                                                                
                                                                  We propose a Gaussian Mixture Importance Estimation (GMIE) approach for ReID, which exploits the Gaussian Mixture Models (GMMs) to estimate the observed commonalities of similar and dissimilar person pairs in the feature space.                                                                                           </tr>
                                    
                              



                                                            <tr onmouseout="icip15_stop()" onmouseover="icip15_start()">
                                                              <td style="padding:20px;width:25%;vertical-align:middle">
                                                                <div class="one">
                                                                        <img src='images/icip15.png' width=130%>
                                                                </div>
                                                                <script type="text/javascript">
                                                                  function icip15_start() {
                                                                    document.getElementById('icip15_image').style.opacity = "1";
                                                                  }
                                                        
                                                                  function icip15_stop() {
                                                                    document.getElementById('icip15_image').style.opacity = "0";
                                                                  }
                                                                  icip15_stop()
                                                                </script>
                                                              </td>
                                                              <td style="padding:20px;width:75%;vertical-align:middle">
                                                                <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532462">
                                                                  <span class="papertitle">Person re-identification using sparse representation with manifold constraints</span>
                                                                </a>
                                                                <br>
                                                                <a>Behzad Mirmahboub</a>, 
                                                                <a href="http://www.hamedkiani.com/"> Hamed Kiani </a>, 
                                                                <strong>Amran Bhuiyan  </strong>,
                                                                <a href="https://scholar.google.com/citations?user=9tkRoJ4AAAAJ"> Alessandro Perina </a>,
                                                                <a href="https://scholar.google.com/citations?user=ImJz6MsAAAAJ&hl=zh-CN"> Baochang zhang </a>,                                                                
                                                                <a href="https://www.iit.it/people/alessio-delbue"> Alessio Del Bue </a>,
                                                                <a href="https://www.vittoriomurino.com/"> Vittorio Murino </a>
                                                               
                                                                
                                                                                  
                                                                                                                           
                                                                     
                                                               
                                                                  <br>
                                                                  <em>  IEEE International Conference on Image Processing</em>, 2016.
                                                                  <br>
                                                                  <br>
                                                        
                                                                
                                                                  In this paper, we propose a novel framework that combines sparse coding and manifold constraints to extract discriminative information from multi-shot images of one pedestrian for person re-identification across a set of non-overlapped surveillance cameras.
                                                                
                                                                </tr>




                                                                <tr onmouseout="icip_stop()" onmouseover="icip_start()">
                                                                  <td style="padding:20px;width:25%;vertical-align:middle">
                                                                    <div class="one">
                                                                            <img src='images/icip.png' width=100%>
                                                                    </div>
                                                                    <script type="text/javascript">
                                                                      function icip_start() {
                                                                        document.getElementById('icip_image').style.opacity = "1";
                                                                      }
                                                            
                                                                      function icip_stop() {
                                                                        document.getElementById('icip_image').style.opacity = "0";
                                                                      }
                                                                      icip_stop()
                                                                    </script>
                                                                  </td>
                                                                  <td style="padding:20px;width:75%;vertical-align:middle">
                                                                    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532462">
                                                                      <span class="papertitle">Exploiting multiple detections to learn robust brightness transfer functions in re-identification systems</span>
                                                                    </a>
                                                                    <br>
                                                                   
                                                                    <strong>Amran Bhuiyan  </strong>,                                                                   
<a href="https://scholar.google.com/citations?user=9tkRoJ4AAAAJ"> Alessandro Perina </a>,

<a href="https://www.vittoriomurino.com/"> Vittorio Murino </a>
                                                                   
                                                                    
                                                                                      
                                                                                                                               
                                                                         
                                                                   
                                                                      <br>
                                                                      <em>  IEEE International Conference on Image Processing</em>, 2015.
                                                                      <br>
                                                                      <br>
                                                            
                                                                    
                                                                      This paper proposes the use of Cumulative Weighted Brightness Transfer Functions to model this appearance variations. It is multiple frame-based learning approach which leverages consecutive detections of each individual to transfer the appearance, rather than learning brightness transfer function from pairs of images.                                                                     
                                                                    </tr>      
                                                                    
                                                                    
                                                                <tr onmouseout="iciap_stop()" onmouseover="iciap_start()">
                                                                  <td style="padding:20px;width:25%;vertical-align:middle">
                                                                    <div class="one">
                                                                            <img src='images/iciap.png' width=100%>
                                                                    </div>
                                                                    <script type="text/javascript">
                                                                      function iciap_start() {
                                                                        document.getElementById('iciap_image').style.opacity = "1";
                                                                      }
                                                            
                                                                      function iciap_stop() {
                                                                        document.getElementById('iciap_image').style.opacity = "0";
                                                                      }
                                                                      iciap_stop()
                                                                    </script>
                                                                  </td>
                                                                  <td style="padding:20px;width:75%;vertical-align:middle">
                                                                    <a href="https://link.springer.com/chapter/10.1007/978-3-319-23234-8_42">
                                                                      <span class="papertitle">Person Re-identification Using Robust Brightness Transfer Functions Based on Multiple Detections</span>
                                                                    </a>
                                                                    <br>
                                                                   
                                                                    <strong>Amran Bhuiyan  </strong>, 
                                                                    <a> Behzad Mirmahboub</a>,                                                                   
<a href="https://scholar.google.com/citations?user=9tkRoJ4AAAAJ"> Alessandro Perina </a>,

<a href="https://www.vittoriomurino.com/"> Vittorio Murino </a>
                                                                   
                                                                    
                                                                                      
                                                                                                                               
                                                                         
                                                                   
                                                                      <br>
                                                                      <em> International Conference on Image Analysis and Processing </em>, 2015.
                                                                      <br>
                                                                      <br>
                                                            
                                                                    
                                                                      This paper proposes the use of Minimum Multiple Cumulative Brightness Transfer Functions to model this appearance variations. It is multiple frame-based learning approach which leverages consecutive detections of each individual to transfer the appearance, rather than learning brightness transfer function from pairs of images.
                                                                                                                                        </tr>      




                                                                                                                                        <tr onmouseout="eccvw_stop()" onmouseover="eccvw_start()">
                                                                                                                                          <td style="padding:20px;width:25%;vertical-align:middle">
                                                                                                                                            <div class="one">
                                                                                                                                                    <img src='images/eccvw.png' width=130%>
                                                                                                                                            </div>
                                                                                                                                            <script type="text/javascript">
                                                                                                                                              function eccvw_start() {
                                                                                                                                                document.getElementById('eccvw_image').style.opacity = "1";
                                                                                                                                              }
                                                                                                                                    
                                                                                                                                              function eccvw_stop() {
                                                                                                                                                document.getElementById('eccvw_image').style.opacity = "0";
                                                                                                                                              }
                                                                                                                                              eccvw_stop()
                                                                                                                                            </script>
                                                                                                                                          </td>
                                                                                                                                          <td style="padding:20px;width:75%;vertical-align:middle">
                                                                                                                                            <a href="https://projet.liris.cnrs.fr/imagine/pub/proceedings/ECCV-2014/workshops/w19/05%20-Person%20re-identification%20by%20discriminatively.pdf">
                                                                                                                                              <span class="papertitle">Person re-identification by discriminatively selecting parts and features</span>
                                                                                                                                            </a>
                                                                                                                                            <br>
                                                                                                                                           
                                                                                                                                            <strong>Amran Bhuiyan  </strong>,                                                                   
                                                                        <a href="https://scholar.google.com/citations?user=9tkRoJ4AAAAJ"> Alessandro Perina </a>,
                                                                        
                                                                        <a href="https://www.vittoriomurino.com/"> Vittorio Murino </a>
                                                                                                                                           
                                                                                                                                            
                                                                                                                                                              
                                                                                                                                                                                                       
                                                                                                                                                 
                                                                                                                                           
                                                                                                                                              <br>
                                                                                                                                              <em>  European Conference on Computer Vision (ECCV)- Workshop on Visual Surveillance and Re-Identification (VS-Re-ID)</em>, 2014.
                                                                                                                                              <strong> Winner of the INTEL Best paper award </strong>
                                                                                                                                              <br>
                                                                                                                                              <br>
                                                                                                                                    
                                                                                                                                            
                                                                                                                                              This paper presents a novel appearance-based method for person re-identification. The core idea is to rank and select different body parts on the basis of the discriminating power of their characteristic features. In our approach, we first segment the pedestrian images into meaningful parts, then we extract features from such parts as well as from the whole body and finally, we perform a salience analysis based on regression coefficients. 
                                                                                                                                            
                                                                                                                                            </tr>

                                                                                                                                          </tbody></table>
                                                                                                                                          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                                                                                                                                            <tr>
                                                                                                                                              <td style="padding:0px">
                                                                                                                                                <br>
                                                                                                                                                <p style="text-align:right;font-size:small;">
                                                                                                                                                  Website template from <a href="https://github.com/jonbarron/jonbarron_website"> this great guy!</a> 
                                                                                                                                                </p>
                                                                                                                                              </td>
                                                                                                                                            </tr>
                                                                                                                                          </tbody></table>

  </body>



</html>
